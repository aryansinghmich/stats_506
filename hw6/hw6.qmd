---
title: "hw6"
author: "Aryan Singh"
format:
  html:
    embed-resources: true
    code-fold: true
---

```{r}
# environment set up
pacman::p_load(tidyverse, knitr, Rcpp, e1071, parallel, lme4, infer, data.table)
```

<https://github.com/aryansinghmich/stats_506>

# Problem 1

```{r}
sourceCpp(code = '
#include <Rcpp.h>
using namespace Rcpp;

// [[Rcpp::export]]
double C_mean(NumericVector v) {
  int n = v.length();
  if (n == 0) return NA_REAL;

  double sum = 0.0;
  for (int i = 0; i < n; ++i) {
    sum += v[i];
  }
  return sum / n;
}

// [[Rcpp::export]]
double C_moment(NumericVector v, int k) {
  int n = v.length();
  if (n == 0) return NA_REAL;

  double mu = 0.0;
  for (int i = 0; i < n; ++i) {
    mu += v[i];
  }
  mu /= n;

  double acc = 0.0;
  for (int i = 0; i < n; ++i) {
    double centered = v[i] - mu;
 
    double term = 1.0;
    for (int j = 0; j < k; ++j) {
      term *= centered;
    }
    acc += term;
  }

  return acc / n;
}
')
```

```{r}
set.seed(123)
x <- rnorm(1000)

# 2nd central moment
C_moment(x, 2)
moment(x, order = 2, center = T)
all.equal(C_moment(x, 2), moment(x, order = 2, center = TRUE))

# 3rd central moment
C_moment(x, 3)
moment(x, order = 3, center = T)
all.equal(C_moment(x, 3), moment(x, order = 3, center = TRUE))
```

# Problem 2

```{r}
# from problem set 5 solutions

## Class definition
setClass(
  "waldCI",
  slots = c(
    level = "numeric",
    mean  = "numeric",
    sterr = "numeric"
  )
)

## Validator
setValidity("waldCI", function(object) {
  if (object@level <= 0 | object@level >= 1) {
    stop("level must be in (0, 1)")
  }
  if (object@sterr <= 0) {
    stop("sterr must be positive")
  }
  if (!is.finite(object@sterr)) {
    stop("Infinite CI not supported")
  }
  TRUE
})

## Constructor 

##' Create `waldCI` object. Either `lb` and `ub`, or `mean` and `sterr` must be
##' provided.
##' @param level Confidence level
##' @param lb lower bound, optional
##' @param ub upper bound, optional
##' @param mean mean, optional
##' @param sterr standard error, optional
##' @return A `waldCI` object
makeCI <- function(level,
                   lb = NULL,
                   ub = NULL,
                   mean = NULL,
                   sterr = NULL) {

  have_mean_se <- !is.null(mean)  && !is.null(sterr) &&
                  is.null(lb)     && is.null(ub)
  have_bounds  <- is.null(mean)   && is.null(sterr) &&
                  !is.null(lb)    && !is.null(ub)

  if (have_mean_se) {
    return(new("waldCI", level = level, mean = mean, sterr = sterr))
  } else if (have_bounds) {
    if (lb > ub) {
      stop("lb must be less than ub")
    }
    z     <- qnorm((1 + level) / 2)
    mean  <- (lb + ub) / 2
    sterr <- (ub - lb) / (2 * z)
    return(new("waldCI", level = level, mean = mean, sterr = sterr))
  } else {
    stop("Input must be either lb/ub or mean/sterr")
  }
}

## Internal: get bounds from mean/sterr 

##' Internal function to compute bounds from stored mean/sterr
##' @param ci waldCI object
##' @return A vector of length 2 for lower and upper bounds
.getBounds <- function(ci) {
  z  <- qnorm((1 + ci@level) / 2)
  lb <- ci@mean - z * ci@sterr
  ub <- ci@mean + z * ci@sterr
  c(lb, ub)
}

## show() 

##' Show method for waldCI object
setMethod("show", "waldCI", function(object) {
  bound <- .getBounds(object)
  cat(round(object@level * 100), "% CI: (", bound[1], ", ", bound[2], ")\n", sep = "")
  invisible(object)
})

## Internal accessor helper 

##' Internal function to get a named slot or bound
##' @param object A `waldCI` object
##' @param slotname "level", "mean", "sterr", "lb", or "ub"
.getSlot <- function(object, slotname) {
  if (slotname %in% c("level", "mean", "sterr")) {
    return(slot(object, slotname))
  }
  bounds <- .getBounds(object)
  if (slotname == "lb") {
    bounds[1]
  } else if (slotname == "ub") {
    bounds[2]
  } else {
    stop("Invalid slotname")
  }
}

## Getters 

## level()
if (!isGeneric("level")) {
  setGeneric("level", function(object) standardGeneric("level"))
}
setMethod("level", "waldCI", function(object) .getSlot(object, "level"))

## mean() method for waldCI (S3-style)
mean.waldCI <- function(x, ...) .getSlot(x, "mean")

## sterr()
if (!isGeneric("sterr")) {
  setGeneric("sterr", function(object) standardGeneric("sterr"))
}
setMethod("sterr", "waldCI", function(object) .getSlot(object, "sterr"))

## lb()
if (!isGeneric("lb")) {
  setGeneric("lb", function(object) standardGeneric("lb"))
}
setMethod("lb", "waldCI", function(object) .getSlot(object, "lb"))

## ub()
if (!isGeneric("ub")) {
  setGeneric("ub", function(object) standardGeneric("ub"))
}
setMethod("ub", "waldCI", function(object) .getSlot(object, "ub"))

## Setters 
## level<-
if (!isGeneric("level<-")) {
  setGeneric("level<-", function(x, value) standardGeneric("level<-"))
}
setMethod("level<-", "waldCI", function(x, value) {
  makeCI(level = value,
         mean  = x@mean,
         sterr = x@sterr)
})

## mean<-
if (!isGeneric("mean<-")) {
  setGeneric("mean<-", function(x, value) standardGeneric("mean<-"))
}
setMethod("mean<-", "waldCI", function(x, value) {
  makeCI(level = x@level,
         mean  = value,
         sterr = x@sterr)
})

## sterr<-
if (!isGeneric("sterr<-")) {
  setGeneric("sterr<-", function(x, value) standardGeneric("sterr<-"))
}
setMethod("sterr<-", "waldCI", function(x, value) {
  makeCI(level = x@level,
         mean  = x@mean,
         sterr = value)
})

## lb<-
if (!isGeneric("lb<-")) {
  setGeneric("lb<-", function(x, value) standardGeneric("lb<-"))
}
setMethod("lb<-", "waldCI", function(x, value) {
  bounds <- .getBounds(x)
  makeCI(level = x@level,
         lb    = value,
         ub    = bounds[2])
})

## ub<-
if (!isGeneric("ub<-")) {
  setGeneric("ub<-", function(x, value) standardGeneric("ub<-"))
}
setMethod("ub<-", "waldCI", function(x, value) {
  bounds <- .getBounds(x)
  makeCI(level = x@level,
         lb    = bounds[1],
         ub    = value)
})

## contains / overlap 

##' Check whether a CI contains a scalar
contains <- function(ci, value) {
  stopifnot(is.numeric(value), length(value) == 1)
  bounds <- .getBounds(ci)
  value > bounds[1] & value < bounds[2]
}

##' Check whether two waldCI objects overlap
overlap <- function(ci1, ci2) {
  b1 <- .getBounds(ci1)
  b2 <- .getBounds(ci2)
  max(b1[1], b2[1]) <= min(b1[2], b2[2])
}

## as.numeric 

if (!isGeneric("as.numeric")) {
  setGeneric("as.numeric", function(x, ...) standardGeneric("as.numeric"))
}
setMethod("as.numeric", "waldCI", function(x, ...) .getBounds(x))

## transformCI 

##' Apply a monotonic transformation to a `waldCI`
##'
##' Monotonic functions are *not* enforced, but non-monotonic functions that
##' return nonsense results (e.g. ub < lb) will likely error.
transformCI <- function(ci, fn) {
  stopifnot(is.function(fn))
  stopifnot(is(ci, "waldCI"))
  makeCI(
    level = ci@level,
    mean  = fn(ci@mean),
    sterr = fn(ci@sterr)
  )
}
```

## Part A
```{r}
## internal helper for bootstrap resampling
##'
##' takes either a data.frame/matrix or a vector object
##' and returns a bootstrap resample of the same size using sampling
##' with replacement
##'
##' @param dat data.frame, matrix, or vector object to be resampled
##'
##' @return bootstrap resample of \code{dat} with the same number of rows
##'   (for data.frames/matrices) or the same length (for vectors)
.bootstrap_sample <- function(dat) {
  if (is.data.frame(dat) || is.matrix(dat)) {
    idx <- sample.int(nrow(dat), replace = T)
    dat[idx, , drop = F]
  } else {
    idx <- sample.int(length(dat), replace = T)
    dat[idx]
  }
}

##' bootstrapWaldCI class
##'
##' S4 class that extends \code{waldCI} to store bootstrap-based
##' Wald confidence intervals
##'
##' @slot FUN function used to compute the scalar statistic on resampled data
##' @slot data original data passed to the constructor
##' @slot reps no. of bootstrap reps
##' @slot compute either "serial" or "parallel"
##' @slot boot numeric vector of bootstrap draws of the statistic
setClass("bootstrapWaldCI",
         slots = list(
           FUN = "function", 
           data = "ANY", 
           reps = "integer", 
           compute = "character", 
           boot = "numeric" # bootstrap draws
         ),
         contains = "waldCI",
         validity = function(object) {
           msgs <- character()

           if (!object@compute %in% c("serial","parallel"))
             msgs <- c(msgs, "compute must be 'serial' or 'parallel'")

           if (length(object@reps) != 1L || object@reps <= 0)
             msgs <- c(msgs, "reps must be a positive integer")

           if (length(object@boot) != as.integer(object@reps))
             msgs <- c(msgs, "length(boot) must equal reps")

           if (length(msgs)) msgs else TRUE
         })

## constructor

##' `bootstrapWaldCI` object using a bootstrap
##'
##' @param FUN function taking data and returning a scalar
##' @param data data to be resampled
##' @param reps no. of bootstrap reps
##' @param level conf level
##' @param compute either "serial" or "parallel"
##' @return \code{bootstrapWaldCI} object
makeBootstrapCI <- function(FUN, data, reps = 1000L, level = 0.95, compute = c("serial","parallel")) {
  compute <- match.arg(compute)
  reps <- as.integer(reps)

  one_boot <- function(i) {
    dat_star <- .bootstrap_sample(data)
    FUN(dat_star)
  }

  if (compute == "serial") {
    boot_vals <- replicate(reps, one_boot(1L))
  } else {
    cores <- min(detectCores(), reps)
    boot_vals <- unlist(mclapply(seq_len(reps), one_boot, mc.cores = cores))
  }

  m <- mean(boot_vals)
  se <- sd(boot_vals)
  z <- qnorm((1 + level)/2)
  lb <- m - z*se
  ub <- m + z*se

  obj <- methods::new("bootstrapWaldCI", level = level, mean = m, sterr = se, FUN = FUN, data = data, reps = reps, compute = compute, boot = boot_vals)

  validObject(obj)
  obj
}

## rebootstrap

##' rerun the bootstrap for a `bootstrapWaldCI` object
##'
##' @param x a \code{bootstrapWaldCI} object
##' @return same object with updated bootstrap draws and CI
if (!isGeneric("rebootstrap")) {
  setGeneric("rebootstrap", function(x) standardGeneric("rebootstrap"))
}

setMethod("rebootstrap", "bootstrapWaldCI",
    function(x) {
        data <- x@data
        FUN <- x@FUN
        reps <- x@reps
        level <- x@level
        compute <- x@compute

        one_boot <- function(i) {
            dat_star <- .bootstrap_sample(data)
            FUN(dat_star)
        }

        if (compute == "serial") {
            boot_vals <- replicate(reps, one_boot(1L))
        } else {
            cores <- min(detectCores(), reps)
            boot_vals <- unlist(mclapply(seq_len(reps), one_boot, mc.cores = cores))
        }

        m <- mean(boot_vals)
        se <- sd(boot_vals)
        z <- qnorm((1 + level)/2)

        x@boot <- boot_vals
        x@mean <- m
        x@sterr <- se

        validObject(x)
        x
    }
)
```

## Part B

```{r}
ci1 <- makeBootstrapCI(function(x) mean(x$y),
                       ggplot2::diamonds,
                       reps = 1000)
ci1
rebootstrap(ci1)
```

Both serial and parallel produce nearly identical intervals, but the parallel option runs faster for larger bootstrap sizes.

## Part C

```{r}
##' extract coef for `disp` from a linear model
##'
##' @param dat data frame with columns mpg, cyl, disp, wt
##' @return coefficient on `disp` from lm(mpg ~ cyl + disp + wt)
dispCoef <- function(dat) {
  fit <- lm(mpg ~ cyl + disp + wt, data = dat)
  coef(fit)["disp"]
}

ci2 <- makeBootstrapCI(dispCoef, mtcars, reps = 1000)
ci2
rebootstrap(ci2)

ci2_serial <- makeBootstrapCI(dispCoef, mtcars, reps = 5000, compute = "serial")
ci2_parallel <- makeBootstrapCI(dispCoef, mtcars, reps = 5000, compute = "parallel")
```

95% CI: (-0.01089946, 0.02583308)
95% CI: (-0.01092147, 0.02608821)

# Problem 3

## Part A

```{r}
source("./ps6_q3.R")
df_std <- df %>%
  group_by(country) %>%
  mutate(
    prior_gpa_z = as.numeric(scale(prior_gpa)),
    forum_posts_z = as.numeric(scale(forum_posts)),
    quiz_attempts_z = as.numeric(scale(quiz_attempts))
  ) %>% ungroup()

countries <- levels(df_std$country)

fit_one <- function(cty) {
  dat <- df_std %>% filter(country == cty)

  t <- system.time(
    mod <- glmer(
      completed_course ~ prior_gpa_z + forum_posts_z + quiz_attempts_z + (1 | device_type),
      data = dat,
      family = binomial
    )
  )
  list(model = mod, time = t)
}

fits <- lapply(countries, fit_one)
names(fits) <- countries

coef_forum <- purrr::map_dfr(seq_along(countries), function(i) {
  cty <- countries[i]
  mod <- fits[[i]]$model
  s <- coef(summary(mod))
  est <- s["forum_posts_z", "Estimate"]
  se  <- s["forum_posts_z", "Std. Error"]

  tibble(
    country = cty,
    estimate = est,
    se = se,
    lower = est - 1.96*se,
    upper = est + 1.96*se
  )
})

ggplot(coef_forum, aes(x = country, y = estimate)) +
  geom_hline(yintercept = 0, linetype = "dashed", linewidth = 0.4) + geom_point() +
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.1) +
  labs(
    x = "Country",
    y = "Effect of forum posts (log-odds)",
    title = "Estimated effect of forum posts on course completion by country"
  )

times <- tibble(
  country = countries,
  user = sapply(fits, function(x) x$time["user.self"]),
  system = sapply(fits, function(x) x$time["sys.self"]),
  elapsed = sapply(fits, function(x) x$time["elapsed"])
)
times
```

## Part B

```{r}
time_b <- system.time({
  df_std_b <- df %>%
    group_by(country) %>%
    mutate(
      prior_gpa_z = as.numeric(scale(prior_gpa)),
      forum_posts_z = as.numeric(scale(forum_posts)),
      quiz_attempts_z = as.numeric(scale(quiz_attempts))
    ) %>% ungroup()
  split_dat <- split(df_std_b, df_std_b$country)

  fit_fun <- function(dat) {
    glmer(
      completed_course ~ prior_gpa_z + forum_posts_z + quiz_attempts_z + (1 | device_type),
      data = dat,
      family = binomial
    )
  }

  fits_b <- mclapply(split_dat, fit_fun, mc.cores = min(length(split_dat), detectCores()))

  # extract forum_posts_z coefficient SE for ea country
  coef_forum_b <- lapply(names(fits_b), function(cty) {
    s <- coef(summary(fits_b[[cty]]))
    est <- s["forum_posts_z", "Estimate"]
    se  <- s["forum_posts_z", "Std. Error"]
    data.frame(
      country = cty,
      estimate = est,
      se = se,
      lower = est - 1.96*se,
      upper = est + 1.96*se,
      row.names = NULL
    )
  }) %>% bind_rows()
})

time_b 
coef_forum_b

left_join(coef_forum %>% arrange(country), coef_forum_b %>% arrange(country), by = "country", suffix = c("_A", "_B")) %>% mutate(diff = estimate_B - estimate_A)
```

The parallelized version produces identical coefficient estimates to part A, but it substantially reduces the total running time by pre-splitting the data and fitting all six models simultaneously.

# Problem 4

```{r}
atp_2019 <- fread("https://raw.githubusercontent.com/JeffSackmann/tennis_atp/refs/heads/master/atp_matches_2019.csv")
```

## Part A

```{r}
tournaments <- unique(atp_2019[, .(tourney_id, tourney_name, tourney_level)])
tournaments[order(tourney_level, tourney_name)][, .(num_tournaments = .N)] %>% as.data.frame() %>% kable()
```

There were 128 ATP tournaments in 2019 in this dataset.

## Part B

```{r}
multi_winners <- atp_2019[round == "F", .(num_tournaments_won = uniqueN(tourney_id)), by = winner_name][num_tournaments_won > 1][order(-num_tournaments_won)]
multi_winners %>% as.data.frame() %>% kable()

multi_winners[, .(num_players_more_than_one = .N, max_tournaments_won = max(num_tournaments_won))] %>% 
  as.data.frame() %>% kable()
```

In the 2019 ATP season, 12 players won more than one tournament. The players with the highest number of tournament victories were Dominic Thiem and Novak Djokovic, with each winning 5 tournaments.

## Part C

```{r}
aces_long <- melt(atp_2019, measure.vars = c("w_ace", "l_ace"), variable.name = "player_type", value.name = "aces")[!is.na(aces)]

aces_long[, player_type := ifelse(player_type == "w_ace", "Winner", "Loser")]

aces_long[, .(mean_aces = mean(aces), sd_aces = sd(aces), n = .N), by = player_type] %>% as.data.frame() %>% kable()

obs_diff <- aces_long %>% specify(aces ~ player_type) %>%
  calculate(stat = "diff in means", order = c("Winner", "Loser")) %>% pull(stat)

null_dist <- aces_long %>% specify(aces ~ player_type) %>%
  hypothesize(null = "independence") %>%
  generate(reps = 5000, type = "permute") %>%
  calculate(stat = "diff in means", order = c("Winner", "Loser"))

p_val <- null_dist %>% get_p_value(obs_stat = obs_diff, direction = "greater")

data.frame(observed_diff = obs_diff, p_value = p_val$p_value) %>% kable()
```

The average number of aces for winners (~ 7.50) is statistically higher than for losers (~ 5.79), yielding an observed mean difference of 1.70 aces per match (permutation test produced a p-value ~ 0)

## Part D

```{r}
players_long <- melt(atp_2019, measure.vars = c("winner_name", "loser_name"), variable.name = "match_result", value.name = "player_name")
players_long[, is_win := as.integer(match_result == "winner_name")]

player_stats <- players_long[, {
  wins <- sum(is_win, na.rm = T)
  .(matches = .N,
    wins = wins,
    win_rate = wins / .N)
}, by = player_name]

best_players <- player_stats[matches >= 5]
best_players[win_rate == max(win_rate)][order(-win_rate)] %>% as.data.frame() %>% kable()
```

Rafael Nadal had the highest win rate among players with at least five matches in 2019. He played 69 matches and won 60, giving him a win rate of approximately ~0.87 (86.96%).